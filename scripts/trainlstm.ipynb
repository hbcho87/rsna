{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv, gzip, os, sys, gc\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import logging\n",
    "import datetime\n",
    "import optparse\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import log_loss\n",
    "import ast\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.ndimage import uniform_filter\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "from apex.fp16_utils import *\n",
    "from apex import amp, optimizers\n",
    "from apex.multi_tensor_apply import multi_tensor_applier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print info about environments\n",
    "parser = optparse.OptionParser()\n",
    "parser.add_option('-s', '--seed', action=\"store\", dest=\"seed\", help=\"model seed\", default=\"1234\")\n",
    "parser.add_option('-o', '--fold', action=\"store\", dest=\"fold\", help=\"Fold for split\", default=\"0\")\n",
    "parser.add_option('-p', '--nbags', action=\"store\", dest=\"nbags\", help=\"Number of bags for averaging\", default=\"4\")\n",
    "parser.add_option('-e', '--epochs', action=\"store\", dest=\"epochs\", help=\"epochs\", default=\"10\")\n",
    "parser.add_option('-b', '--batchsize', action=\"store\", dest=\"batchsize\", help=\"batch size\", default=\"4\")\n",
    "parser.add_option('-r', '--rootpath', action=\"store\", dest=\"rootpath\", help=\"root directory\", default=\"\")\n",
    "parser.add_option('-i', '--imgpath', action=\"store\", dest=\"imgpath\", help=\"root directory\", default=\"data/mount/512X512X6/\")\n",
    "parser.add_option('-w', '--workpath', action=\"store\", dest=\"workpath\", help=\"Working path\", default=\"densenetv1/weights\")\n",
    "parser.add_option('-f', '--weightsname', action=\"store\", dest=\"weightsname\", help=\"Weights file name\", default=\"pytorch_model.bin\")\n",
    "parser.add_option('-l', '--lr', action=\"store\", dest=\"lr\", help=\"learning rate\", default=\"0.00005\")\n",
    "parser.add_option('-g', '--logmsg', action=\"store\", dest=\"logmsg\", help=\"root directory\", default=\"Recursion-pytorch\")\n",
    "parser.add_option('-c', '--size', action=\"store\", dest=\"size\", help=\"model size\", default=\"480\")\n",
    "parser.add_option('-a', '--globalepoch', action=\"store\", dest=\"globalepoch\", help=\"root directory\", default=\"3\")\n",
    "parser.add_option('-n', '--loadcsv', action=\"store\", dest=\"loadcsv\", help=\"Convert csv embeddings to numpy\", default=\"F\")\n",
    "parser.add_option('-j', '--lstm_units', action=\"store\", dest=\"lstm_units\", help=\"Lstm units\", default=\"128\")\n",
    "parser.add_option('-d', '--dropout', action=\"store\", dest=\"dropout\", help=\"LSTM input spatial dropout\", default=\"0.3\")\n",
    "parser.add_option('-z', '--decay', action=\"store\", dest=\"decay\", help=\"Weight Decay\", default=\"0.0\")\n",
    "parser.add_option('-m', '--lrgamma', action=\"store\", dest=\"lrgamma\", help=\"Scheduler Learning Rate Gamma\", default=\"1.0\")\n",
    "parser.add_option('-k', '--ttahflip', action=\"store\", dest=\"ttahflip\", help=\"Bag with horizontal flip on and off\", default=\"F\")\n",
    "parser.add_option('-q', '--ttatranspose', action=\"store\", dest=\"ttatranspose\", help=\"Bag with horizontal flip on and off\", default=\"F\")\n",
    "parser.add_option('-x', '--datapath', action=\"store\", dest=\"datapath\", help=\"Data path\", default=\"data\")\n",
    "\n",
    "\n",
    "options, args = parser.parse_args()\n",
    "package_dir = options.rootpath\n",
    "sys.path.append(package_dir)\n",
    "sys.path.insert(0, 'scripts')\n",
    "from logs import get_logger\n",
    "from utils import dumpobj, loadobj, GradualWarmupScheduler\n",
    "\n",
    "options.logmsg = \"Rsna-lstm-0-1-fp16\"\n",
    "options.epochs = 12\n",
    "options.fold = 1\n",
    "options.lr = 0.00001\n",
    "options.batchsize = 4\n",
    "options.workpath = '/bin/resnext101v12fold1'\n",
    "options.datapath = '/bin/resnext101v12fold1'\n",
    "options.lrgamma = 0.95\n",
    "options.nbags = 12\n",
    "options.globalepoch = 0\n",
    "options.lstm_units = 2048\n",
    "options.size = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-29 09:38:33,519 - Rsna-lstm-0-1-fp16 - INFO - Cuda set up : time 09:38:33.519203\n",
      "2020-04-29 09:38:33,519 - Rsna-lstm-0-1-fp16 - INFO - Cuda set up : time 09:38:33.519203\n",
      "2020-04-29 09:38:33,521 - Rsna-lstm-0-1-fp16 - INFO - Device : GeForce GTX 1080 Ti\n",
      "2020-04-29 09:38:33,521 - Rsna-lstm-0-1-fp16 - INFO - Device : GeForce GTX 1080 Ti\n",
      "2020-04-29 09:38:33,525 - Rsna-lstm-0-1-fp16 - INFO - Cuda available : True\n",
      "2020-04-29 09:38:33,525 - Rsna-lstm-0-1-fp16 - INFO - Cuda available : True\n",
      "2020-04-29 09:38:33,526 - Rsna-lstm-0-1-fp16 - INFO - Cuda n_gpus : 5\n",
      "2020-04-29 09:38:33,526 - Rsna-lstm-0-1-fp16 - INFO - Cuda n_gpus : 5\n",
      "2020-04-29 09:38:33,528 - Rsna-lstm-0-1-fp16 - INFO - Load params : time 09:38:33.528839\n",
      "2020-04-29 09:38:33,528 - Rsna-lstm-0-1-fp16 - INFO - Load params : time 09:38:33.528839\n",
      "2020-04-29 09:38:33,533 - Rsna-lstm-0-1-fp16 - INFO - seed                1234\n",
      "2020-04-29 09:38:33,533 - Rsna-lstm-0-1-fp16 - INFO - seed                1234\n",
      "2020-04-29 09:38:33,534 - Rsna-lstm-0-1-fp16 - INFO - fold                1\n",
      "2020-04-29 09:38:33,534 - Rsna-lstm-0-1-fp16 - INFO - fold                1\n",
      "2020-04-29 09:38:33,534 - Rsna-lstm-0-1-fp16 - INFO - nbags               12\n",
      "2020-04-29 09:38:33,534 - Rsna-lstm-0-1-fp16 - INFO - nbags               12\n",
      "2020-04-29 09:38:33,535 - Rsna-lstm-0-1-fp16 - INFO - epochs              12\n",
      "2020-04-29 09:38:33,535 - Rsna-lstm-0-1-fp16 - INFO - epochs              12\n",
      "2020-04-29 09:38:33,536 - Rsna-lstm-0-1-fp16 - INFO - batchsize           4\n",
      "2020-04-29 09:38:33,536 - Rsna-lstm-0-1-fp16 - INFO - batchsize           4\n",
      "2020-04-29 09:38:33,537 - Rsna-lstm-0-1-fp16 - INFO - rootpath            \n",
      "2020-04-29 09:38:33,537 - Rsna-lstm-0-1-fp16 - INFO - rootpath            \n",
      "2020-04-29 09:38:33,538 - Rsna-lstm-0-1-fp16 - INFO - imgpath             data/mount/512X512X6/\n",
      "2020-04-29 09:38:33,538 - Rsna-lstm-0-1-fp16 - INFO - imgpath             data/mount/512X512X6/\n",
      "2020-04-29 09:38:33,539 - Rsna-lstm-0-1-fp16 - INFO - workpath            /bin/resnext101v12fold1\n",
      "2020-04-29 09:38:33,539 - Rsna-lstm-0-1-fp16 - INFO - workpath            /bin/resnext101v12fold1\n",
      "2020-04-29 09:38:33,540 - Rsna-lstm-0-1-fp16 - INFO - weightsname         /home/hbcho/.local/share/jupyter/runtime/kernel-5a145b97-bbd8-4038-aa07-20f68551adaa.json\n",
      "2020-04-29 09:38:33,540 - Rsna-lstm-0-1-fp16 - INFO - weightsname         /home/hbcho/.local/share/jupyter/runtime/kernel-5a145b97-bbd8-4038-aa07-20f68551adaa.json\n",
      "2020-04-29 09:38:33,541 - Rsna-lstm-0-1-fp16 - INFO - lr                  1e-05\n",
      "2020-04-29 09:38:33,541 - Rsna-lstm-0-1-fp16 - INFO - lr                  1e-05\n",
      "2020-04-29 09:38:33,541 - Rsna-lstm-0-1-fp16 - INFO - logmsg              Rsna-lstm-0-1-fp16\n",
      "2020-04-29 09:38:33,541 - Rsna-lstm-0-1-fp16 - INFO - logmsg              Rsna-lstm-0-1-fp16\n",
      "2020-04-29 09:38:33,542 - Rsna-lstm-0-1-fp16 - INFO - size                480\n",
      "2020-04-29 09:38:33,542 - Rsna-lstm-0-1-fp16 - INFO - size                480\n",
      "2020-04-29 09:38:33,543 - Rsna-lstm-0-1-fp16 - INFO - globalepoch         0\n",
      "2020-04-29 09:38:33,543 - Rsna-lstm-0-1-fp16 - INFO - globalepoch         0\n",
      "2020-04-29 09:38:33,544 - Rsna-lstm-0-1-fp16 - INFO - loadcsv             F\n",
      "2020-04-29 09:38:33,544 - Rsna-lstm-0-1-fp16 - INFO - loadcsv             F\n",
      "2020-04-29 09:38:33,545 - Rsna-lstm-0-1-fp16 - INFO - lstm_units          2048\n",
      "2020-04-29 09:38:33,545 - Rsna-lstm-0-1-fp16 - INFO - lstm_units          2048\n",
      "2020-04-29 09:38:33,546 - Rsna-lstm-0-1-fp16 - INFO - dropout             0.3\n",
      "2020-04-29 09:38:33,546 - Rsna-lstm-0-1-fp16 - INFO - dropout             0.3\n",
      "2020-04-29 09:38:33,547 - Rsna-lstm-0-1-fp16 - INFO - decay               0.0\n",
      "2020-04-29 09:38:33,547 - Rsna-lstm-0-1-fp16 - INFO - decay               0.0\n",
      "2020-04-29 09:38:33,547 - Rsna-lstm-0-1-fp16 - INFO - lrgamma             0.95\n",
      "2020-04-29 09:38:33,547 - Rsna-lstm-0-1-fp16 - INFO - lrgamma             0.95\n",
      "2020-04-29 09:38:33,548 - Rsna-lstm-0-1-fp16 - INFO - ttahflip            F\n",
      "2020-04-29 09:38:33,548 - Rsna-lstm-0-1-fp16 - INFO - ttahflip            F\n",
      "2020-04-29 09:38:33,549 - Rsna-lstm-0-1-fp16 - INFO - ttatranspose        F\n",
      "2020-04-29 09:38:33,549 - Rsna-lstm-0-1-fp16 - INFO - ttatranspose        F\n",
      "2020-04-29 09:38:33,550 - Rsna-lstm-0-1-fp16 - INFO - datapath            /bin/resnext101v12fold1\n",
      "2020-04-29 09:38:33,550 - Rsna-lstm-0-1-fp16 - INFO - datapath            /bin/resnext101v12fold1\n"
     ]
    }
   ],
   "source": [
    "# Print info about environments\n",
    "logger = get_logger(options.logmsg, 'INFO') # noqa\n",
    "logger.info('Cuda set up : time {}'.format(datetime.datetime.now().time()))\n",
    "\n",
    "device=torch.device('cuda')\n",
    "logger.info('Device : {}'.format(torch.cuda.get_device_name(0)))\n",
    "logger.info('Cuda available : {}'.format(torch.cuda.is_available()))\n",
    "n_gpu = torch.cuda.device_count()\n",
    "logger.info('Cuda n_gpus : {}'.format(n_gpu ))\n",
    "\n",
    "logger.info('Load params : time {}'.format(datetime.datetime.now().time()))\n",
    "for (k,v) in options.__dict__.items():\n",
    "    logger.info('{}{}'.format(k.ljust(20), v))\n",
    "    \n",
    "SEED = int(options.seed)\n",
    "SIZE = int(options.size)\n",
    "EPOCHS = int(options.epochs)\n",
    "GLOBALEPOCH=int(options.globalepoch)\n",
    "n_epochs = EPOCHS \n",
    "lr=float(options.lr)\n",
    "lrgamma=float(options.lrgamma)\n",
    "DECAY=float(options.decay)\n",
    "batch_size = int(options.batchsize)\n",
    "ROOT = options.rootpath\n",
    "path_data = os.path.join(ROOT, options.datapath)\n",
    "WORK_DIR = os.path.join(ROOT, options.workpath)\n",
    "path_emb = os.path.join(ROOT, options.workpath)\n",
    "\n",
    "WEIGHTS_NAME = options.weightsname\n",
    "fold = int(options.fold)\n",
    "LOADCSV= options.loadcsv=='T'\n",
    "LSTM_UNITS=int(options.lstm_units)\n",
    "nbags=int(options.nbags)\n",
    "DROPOUT=float(options.dropout)\n",
    "TTAHFLIP= 'T' if options.ttahflip=='T' else ''\n",
    "TTATRANSPOSE= 'P' if options.ttatranspose=='T' else ''\n",
    "n_classes = 6\n",
    "label_cols = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSub(ypred, imgs):\n",
    "    imgls = np.array(imgs).repeat(len(label_cols)) \n",
    "    icdls = pd.Series(label_cols*ypred.shape[0])   \n",
    "    yidx = ['{}_{}'.format(i,j) for i,j in zip(imgls, icdls)]\n",
    "    subdf = pd.DataFrame({'ID' : yidx, 'Label': ypred.flatten()})\n",
    "    return subdf\n",
    "\n",
    "class SpatialDropout(nn.Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x\n",
    "\n",
    "def criterion(data, targets, criterion = torch.nn.BCEWithLogitsLoss()):\n",
    "    ''' Define custom loss function for weighted BCE on 'target' column '''\n",
    "    loss_all = criterion(data, targets)\n",
    "    loss_any = criterion(data[:,-1:], targets[:,-1:])\n",
    "    return (loss_all*6 + loss_any*1)/7\n",
    "\n",
    "class IntracranialDataset(Dataset):\n",
    "    def __init__(self, df, mat, labels=label_cols):\n",
    "        self.data = df\n",
    "        self.mat = mat\n",
    "        self.labels = labels\n",
    "        self.patients = df.SliceID.unique()\n",
    "        self.data = self.data.set_index('SliceID')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patients)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        patidx = self.patients[idx]\n",
    "        patdf = self.data.loc[patidx].sort_values('seq')\n",
    "        patemb = self.mat[patdf['embidx'].values]\n",
    "\n",
    "        patdeltalag  = np.zeros(patemb.shape)\n",
    "        patdeltalead = np.zeros(patemb.shape)\n",
    "        patdeltalag [1:] = patemb[1:]-patemb[:-1]\n",
    "        patdeltalead[:-1] = patemb[:-1]-patemb[1:]\n",
    "\n",
    "        patemb = np.concatenate((patemb, patdeltalag, patdeltalead), -1)\n",
    "        \n",
    "        ids = torch.tensor(patdf['embidx'].values)\n",
    "\n",
    "        if self.labels:\n",
    "            labels = torch.tensor(patdf[label_cols].values)\n",
    "            return {'emb': patemb, 'embidx' : ids, 'labels': labels}    \n",
    "        else:      \n",
    "            return {'emb': patemb, 'embidx' : ids}\n",
    "\n",
    "def predict(loader):\n",
    "    valls = []\n",
    "    imgls = []\n",
    "    imgdf = loader.dataset.data.reset_index().set_index('embidx')[['Image']].copy()\n",
    "    for step, batch in enumerate(loader):\n",
    "        inputs = batch[\"emb\"]\n",
    "        mask = batch['mask'].to(device, dtype=torch.int)\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        logits = model(inputs)\n",
    "        # get the mask for masked labels\n",
    "        maskidx = mask.view(-1)==1\n",
    "        # reshape for\n",
    "        logits = logits.view(-1, n_classes)[maskidx]\n",
    "        valls.append(torch.sigmoid(logits).detach().cpu().numpy())\n",
    "        # Get the list of images\n",
    "        embidx = batch[\"embidx\"].detach().cpu().numpy().astype(np.int32)\n",
    "        embidx = embidx.flatten()[embidx.flatten()>-1]\n",
    "        images = imgdf.loc[embidx].Image.tolist() \n",
    "        imgls += images\n",
    "    return np.concatenate(valls, 0), imgls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 17:07:46,074 - Rsna-lstm-0-1-fp16 - INFO - Cuda set up : time 17:07:46.074394\n"
     ]
    }
   ],
   "source": [
    "# Print info about environments\n",
    "logger.info('Cuda set up : time {}'.format(datetime.datetime.now().time()))\n",
    "\n",
    "# Get image sequences\n",
    "trnmdf = pd.read_csv(os.path.join(path_data, 'train_metadata.csv.gz'))\n",
    "tstmdf = pd.read_csv(os.path.join(path_data, 'test_metadata.csv.gz'))\n",
    "\n",
    "trnmdf['SliceID'] = trnmdf[['PatientID', 'SeriesInstanceUID', 'StudyInstanceUID']].apply(lambda x: '{}__{}__{}'.format(*x.tolist()), 1)\n",
    "tstmdf['SliceID'] = tstmdf[['PatientID', 'SeriesInstanceUID', 'StudyInstanceUID']].apply(lambda x: '{}__{}__{}'.format(*x.tolist()), 1)\n",
    "\n",
    "poscols = ['ImagePos{}'.format(i) for i in range(1, 4)]\n",
    "trnmdf[poscols] = pd.DataFrame(trnmdf['ImagePositionPatient']\\\n",
    "              .apply(lambda x: list(map(float, ast.literal_eval(x)))).tolist())\n",
    "tstmdf[poscols] = pd.DataFrame(tstmdf['ImagePositionPatient']\\\n",
    "              .apply(lambda x: list(map(float, ast.literal_eval(x)))).tolist())\n",
    "\n",
    "trnmdf['seq'] = (trnmdf.groupby(['SliceID']).cumcount() + 1)\n",
    "tstmdf['seq'] = (tstmdf.groupby(['SliceID']).cumcount() + 1)\n",
    "\n",
    "keepcols = ['PatientID', 'SliceID', 'SOPInstanceUID', 'seq']\n",
    "trnmdf = trnmdf[keepcols]\n",
    "tstmdf = tstmdf[keepcols]\n",
    "\n",
    "trnmdf.columns = tstmdf.columns = ['PatientID', 'SliceID', 'Image', 'seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 17:16:54,131 - Rsna-lstm-0-1-fp16 - INFO - Trn df shape 539827 12\n",
      "2020-04-28 17:16:54,132 - Rsna-lstm-0-1-fp16 - INFO - Val df shape 134430 12\n",
      "2020-04-28 17:16:54,133 - Rsna-lstm-0-1-fp16 - INFO - Tst df shape 78545 6\n"
     ]
    }
   ],
   "source": [
    "# Load Data Frames\n",
    "trndf = loadobj(os.path.join(path_emb, 'loader_trn_size{}_fold{}_ep{}'.format(SIZE, fold, GLOBALEPOCH))).dataset.data\n",
    "valdf = loadobj(os.path.join(path_emb, 'loader_val_size{}_fold{}_ep{}'.format(SIZE, fold, GLOBALEPOCH))).dataset.data\n",
    "tstdf = loadobj(os.path.join(path_emb, 'loader_tst_size{}_fold{}_ep{}'.format(SIZE, fold, GLOBALEPOCH))).dataset.data\n",
    "\n",
    "trndf['embidx'] = range(trndf.shape[0])\n",
    "valdf['embidx'] = range(valdf.shape[0])\n",
    "tstdf['embidx'] = range(tstdf.shape[0])\n",
    "\n",
    "trndf = trndf.merge(trnmdf.drop('PatientID', 1), on = 'Image')\n",
    "valdf = valdf.merge(trnmdf.drop('PatientID', 1), on = 'Image')\n",
    "tstdf = tstdf.merge(tstmdf, on = 'Image')\n",
    "\n",
    "logger.info('Trn df shape {} {}'.format(*trndf.shape))\n",
    "logger.info('Val df shape {} {}'.format(*valdf.shape))\n",
    "logger.info('Tst df shape {} {}'.format(*tstdf.shape))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 17:08:34,999 - Rsna-lstm-0-1-fp16 - INFO - Load npy..\n",
      "2020-04-28 17:08:35,002 - Rsna-lstm-0-1-fp16 - INFO - Load embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings\n",
    "embnm='emb_sz256_wt256_fold{}_epoch{}'.format(fold, GLOBALEPOCH)\n",
    "logger.info('Load npy..')\n",
    "\n",
    "def loademb(TYPE, SIZE, fold, GLOBALEPOCH, TTA=''):\n",
    "    return np.load(os.path.join(path_emb, 'emb{}_{}_size{}_fold{}_ep{}.npz'.format(TTA, TYPE, SIZE, fold, GLOBALEPOCH)))['arr_0']\n",
    "\n",
    "logger.info('Load embeddings...')\n",
    "trnembls = [loademb('trn', SIZE, fold, GLOBALEPOCH)]\n",
    "valembls = [loademb('val', SIZE, fold, GLOBALEPOCH)]\n",
    "tstembls = [loademb('tst', SIZE, fold, GLOBALEPOCH)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 17:15:07,208 - Rsna-lstm-0-1-fp16 - INFO - Trn shape 539827 2048\n",
      "2020-04-28 17:15:07,211 - Rsna-lstm-0-1-fp16 - INFO - Val shape 134430 2048\n",
      "2020-04-28 17:15:07,212 - Rsna-lstm-0-1-fp16 - INFO - Tst shape 78545 2048\n",
      "2020-04-28 17:15:07,213 - Rsna-lstm-0-1-fp16 - INFO - Add stg1 test labels to train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if TTAHFLIP=='T':\n",
    "    logger.info('Load hflip...')\n",
    "    trnembls.append(loademb('trn', SIZE, fold, GLOBALEPOCH, TTA='T'))\n",
    "    valembls.append(loademb('val', SIZE, fold, GLOBALEPOCH, TTA='T'))\n",
    "    tstembls.append(loademb('tst', SIZE, fold, GLOBALEPOCH, TTA='T'))\n",
    "if TTATRANSPOSE=='P':\n",
    "    logger.info('Load transpose...')\n",
    "    trnembls.append(loademb('trn', SIZE, fold, GLOBALEPOCH, TTA='P'))\n",
    "    valembls.append(loademb('val', SIZE, fold, GLOBALEPOCH, TTA='P'))\n",
    "    tstembls.append(loademb('tst', SIZE, fold, GLOBALEPOCH, TTA='P'))\n",
    "\n",
    "trnemb = sum(trnembls)/len(trnembls)\n",
    "valemb = sum(valembls)/len(valembls)\n",
    "tstemb = sum(tstembls)/len(tstembls)\n",
    "\n",
    "logger.info('Trn shape {} {}'.format(*trnemb.shape))\n",
    "logger.info('Val shape {} {}'.format(*valemb.shape))\n",
    "logger.info('Tst shape {} {}'.format(*tstemb.shape))\n",
    "logger.info('Add stg1 test labels to train')\n",
    "del trnembls, valembls, tstembls\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 17:17:05,962 - Rsna-lstm-0-1-fp16 - INFO - Create loaders...\n",
      "2020-04-28 17:17:06,618 - Rsna-lstm-0-1-fp16 - INFO - Create model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n"
     ]
    }
   ],
   "source": [
    "# a simple custom collate function, just to show the idea\n",
    "def collatefn(batch):\n",
    "    maxlen = max([l['emb'].shape[0] for l in batch])\n",
    "    embdim = batch[0]['emb'].shape[1]\n",
    "    withlabel = 'labels' in batch[0]\n",
    "    if withlabel:\n",
    "        labdim= batch[0]['labels'].shape[1]\n",
    "        \n",
    "    for b in batch:\n",
    "        masklen = maxlen-len(b['emb'])\n",
    "        b['emb'] = np.vstack((np.zeros((masklen, embdim)), b['emb']))\n",
    "        b['embidx'] = torch.cat((torch.ones((masklen),dtype=torch.long)*-1, b['embidx']))\n",
    "        b['mask'] = np.ones((maxlen))\n",
    "        b['mask'][:masklen] = 0.\n",
    "        if withlabel:\n",
    "            b['labels'] = np.vstack((np.zeros((maxlen-len(b['labels']), labdim)), b['labels']))\n",
    "            \n",
    "    outbatch = {'emb' : torch.tensor(np.vstack([np.expand_dims(b['emb'], 0) \\\n",
    "                                                for b in batch])).float()}  \n",
    "    outbatch['mask'] = torch.tensor(np.vstack([np.expand_dims(b['mask'], 0) \\\n",
    "                                                for b in batch])).float()\n",
    "    outbatch['embidx'] = torch.tensor(np.vstack([np.expand_dims(b['embidx'], 0) \\\n",
    "                                                for b in batch])).float()\n",
    "    if withlabel:\n",
    "        outbatch['labels'] = torch.tensor(np.vstack([np.expand_dims(b['labels'], 0) for b in batch])).float()\n",
    "    return outbatch\n",
    "\n",
    "logger.info('Create loaders...')\n",
    "trndataset = IntracranialDataset(trndf, trnemb, labels=True)\n",
    "trnloader = DataLoader(trndataset, batch_size=batch_size, shuffle=True, num_workers=8, collate_fn=collatefn)\n",
    "\n",
    "valdataset = IntracranialDataset(valdf, valemb, labels=False)\n",
    "tstdataset = IntracranialDataset(tstdf, tstemb, labels=False)\n",
    "\n",
    "tstloader = DataLoader(tstdataset, batch_size=batch_size*4, shuffle=False, num_workers=8, collate_fn=collatefn)\n",
    "valloader = DataLoader(valdataset, batch_size=batch_size*4, shuffle=False, num_workers=8, collate_fn=collatefn)\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/bminixhofer/speed-up-your-rnn-with-sequence-bucketing\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, embed_size=trnemb.shape[-1]*3, LSTM_UNITS=64, DO = 0.3):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        self.embedding_dropout = SpatialDropout(0.0) #DO)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.linear1 = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n",
    "        self.linear2 = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n",
    "\n",
    "        self.linear = nn.Linear(LSTM_UNITS*2, n_classes)\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        h_embedding = x\n",
    "\n",
    "        h_embadd = torch.cat((h_embedding[:,:,:2048], h_embedding[:,:,:2048]), -1)\n",
    "        \n",
    "        h_lstm1, _ = self.lstm1(h_embedding)\n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_lstm1))\n",
    "        h_conc_linear2  = F.relu(self.linear2(h_lstm2))\n",
    "        \n",
    "        hidden = h_lstm1 + h_lstm2 + h_conc_linear1 + h_conc_linear2 + h_embadd\n",
    "\n",
    "        output = self.linear(hidden)\n",
    "        \n",
    "        return output\n",
    "\n",
    "logger.info('Create model')\n",
    "model =     NeuralNet(LSTM_UNITS=LSTM_UNITS, DO = DROPOUT)\n",
    "model = model.to(device)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "plist = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': DECAY},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = optim.Adam(plist, lr=lr)\n",
    "scheduler = StepLR(optimizer, 1, gamma=lrgamma, last_epoch=-1)\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 18:25:52,064 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.14773\n",
      "2020-04-28 18:28:31,349 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.06730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 18:31:11,145 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.06708\n",
      "2020-04-28 18:33:50,746 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.06701\n",
      "2020-04-28 18:36:25,616 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n",
      "2020-04-28 18:37:10,909 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.03425\n",
      "2020-04-28 18:39:50,247 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.06477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 18:42:29,583 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.06584\n",
      "2020-04-28 18:45:09,279 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.06529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 18:47:38,259 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n",
      "2020-04-28 18:48:09,662 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.02882\n",
      "2020-04-28 18:50:49,013 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.06200\n",
      "2020-04-28 18:53:29,219 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.06234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 18:56:09,298 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.06192\n",
      "2020-04-28 18:58:38,512 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n",
      "2020-04-28 18:59:25,199 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.07879\n",
      "2020-04-28 19:02:04,356 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.05908\n",
      "2020-04-28 19:04:44,202 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.06073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 19:07:23,704 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.06016\n",
      "2020-04-28 19:10:45,195 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n",
      "2020-04-28 19:11:17,322 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.02274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 19:13:56,710 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.05959\n",
      "2020-04-28 19:16:35,782 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.05829\n",
      "2020-04-28 19:19:15,567 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.05855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 19:21:45,659 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n",
      "2020-04-28 19:22:18,357 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.14458\n",
      "2020-04-28 19:24:58,405 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.05627\n",
      "2020-04-28 19:27:38,859 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.05556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 19:30:20,481 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.05607\n",
      "2020-04-28 19:33:01,111 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n",
      "2020-04-28 19:33:35,524 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.06987\n",
      "2020-04-28 19:36:25,489 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.05155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 19:39:15,467 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.05369\n",
      "2020-04-28 19:42:05,982 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.05321\n",
      "2020-04-28 19:44:44,970 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n",
      "2020-04-28 19:45:16,492 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.09910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 19:48:06,055 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.04868\n",
      "2020-04-28 19:50:56,179 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.04874\n",
      "2020-04-28 19:53:41,126 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.04970\n",
      "2020-04-28 19:56:27,617 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n",
      "2020-04-28 19:56:49,017 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.02229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 19:59:39,025 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.04610\n",
      "2020-04-28 20:02:29,097 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.04638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 20:05:19,210 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.04577\n",
      "2020-04-28 20:07:57,449 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n",
      "2020-04-28 20:08:18,664 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.00923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 20:11:09,411 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.04060\n",
      "2020-04-28 20:13:58,412 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.04016\n",
      "2020-04-28 20:16:47,778 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.04087\n",
      "2020-04-28 20:19:25,269 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n",
      "2020-04-28 20:19:46,255 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.05971\n",
      "2020-04-28 20:22:35,504 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.03645\n",
      "2020-04-28 20:25:24,523 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.03616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 20:28:13,416 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.03617\n",
      "2020-04-28 20:30:53,421 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n",
      "2020-04-28 20:31:18,520 - Rsna-lstm-0-1-fp16 - INFO - Trn step 0 of 3909 trn lossavg 0.03559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 20:34:07,371 - Rsna-lstm-0-1-fp16 - INFO - Trn step 1000 of 3909 trn lossavg 0.03041\n",
      "2020-04-28 20:36:56,037 - Rsna-lstm-0-1-fp16 - INFO - Trn step 2000 of 3909 trn lossavg 0.03013\n",
      "2020-04-28 20:39:45,823 - Rsna-lstm-0-1-fp16 - INFO - Trn step 3000 of 3909 trn lossavg 0.03036\n",
      "2020-04-28 20:42:23,425 - Rsna-lstm-0-1-fp16 - INFO - Prep test sub...\n"
     ]
    }
   ],
   "source": [
    "ypredls = []\n",
    "ypredtstls = []\n",
    "if not  os.path.exists(WORK_DIR + '/weights'):\n",
    "    os.mkdir(WORK_DIR + '/weights')\n",
    "for epoch in range(EPOCHS):\n",
    "    tr_loss = 0.\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    model.train()  \n",
    "    for step, batch in enumerate(trnloader):\n",
    "        y = batch['labels'].to(device, dtype=torch.float)\n",
    "        mask = batch['mask'].to(device, dtype=torch.int)\n",
    "        x = batch['emb'].to(device, dtype=torch.float)\n",
    "        x = torch.autograd.Variable(x, requires_grad=True)\n",
    "        y = torch.autograd.Variable(y)\n",
    "        logits = model(x).to(device, dtype=torch.float)\n",
    "        # get the mask for masked labels\n",
    "        maskidx = mask.view(-1)==1\n",
    "        y = y.view(-1, n_classes)[maskidx]\n",
    "        logits = logits.view(-1, n_classes)[maskidx]\n",
    "        # Get loss\n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        optimizer.step()\n",
    "        if step%1000==0:\n",
    "            logger.info('Trn step {} of {} trn lossavg {:.5f}'. \\\n",
    "                        format(step, len(trnloader), (tr_loss/(1+step))))\n",
    "    output_model_file = os.path.join(WORK_DIR, 'weights/lstm_gepoch{}_lstmepoch{}_fold{}.bin'.format(GLOBALEPOCH, epoch, fold))\n",
    "    torch.save(model.state_dict(), output_model_file)\n",
    "\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    '''\n",
    "    logger.info('Prep val score...')\n",
    "    ypred, imgval = predict(valloader)\n",
    "    ypredls.append(ypred)\n",
    "     \n",
    "    yvalpred = sum(ypredls[-nbags:])/len(ypredls[-nbags:])\n",
    "    yvalout = makeSub(yvalpred, imgval)\n",
    "    yvalp = makeSub(ypred, imgval)\n",
    "    \n",
    "    # get Val score\n",
    "    weights = ([1, 1, 1, 1, 1, 2] * ypred.shape[0])\n",
    "    yact = valloader.dataset.data[label_cols].values#.flatten()\n",
    "    yact = makeSub(yact, valloader.dataset.data['Image'].tolist())\n",
    "    yact = yact.set_index('ID').loc[yvalout.ID].reset_index()\n",
    "    valloss = log_loss(yact['Label'].values, yvalp['Label'].values.clip(.00001,.99999) , sample_weight = weights)\n",
    "    vallossavg = log_loss(yact['Label'].values, yvalout['Label'].values.clip(.00001,.99999) , sample_weight = weights)\n",
    "    logger.info('Epoch {} val logloss {:.5f} bagged {:.5f}'.format(epoch, valloss, vallossavg))\n",
    "    '''\n",
    "    logger.info('Prep test sub...')\n",
    "    ypred, imgtst = predict(tstloader)\n",
    "    ypredtstls.append(ypred)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-29 07:28:34,595 - Rsna-lstm-0-1-fp16 - INFO - Write out bagged prediction to preds folder\n"
     ]
    }
   ],
   "source": [
    "if not  os.path.exists('../preds'):\n",
    "    os.mkdir('../preds')\n",
    "\n",
    "logger.info('Write out bagged prediction to preds folder')\n",
    "ytstpred = sum(ypredtstls[-nbags:])/len(ypredtstls[-nbags:])\n",
    "ytstout = makeSub(ytstpred, imgtst)\n",
    "ytstout.to_csv('../preds/lstm{}{}{}_{}_epoch{}_sub_{}.csv.gz'.format(TTAHFLIP, TTATRANSPOSE, LSTM_UNITS, WORK_DIR.split('/')[-1], epoch, embnm), \\\n",
    "            index = False, compression = 'gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
