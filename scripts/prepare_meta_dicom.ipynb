{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "from joblib import delayed, Parallel\n",
    "import zipfile\n",
    "from pydicom.filebase import DicomBytesIO\n",
    "import sys\n",
    "sys.path.insert(0, 'scripts')\n",
    "from logs import get_logger, dumpobj, loadobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:19:42,196 - Prepare Data - INFO - Cuda set up : time 16:19:42.196888\n"
     ]
    }
   ],
   "source": [
    "# Print info about environments\n",
    "logger = get_logger('Prepare Data', 'INFO') # noqa\n",
    "logger.info('Cuda set up : time {}'.format(datetime.datetime.now().time()))\n",
    "\n",
    "def get_dicom_value(x, cast=int):\n",
    "    if type(x) in [pydicom.multival.MultiValue, tuple]:\n",
    "        return cast(x[0])\n",
    "    else:\n",
    "        return cast(x)\n",
    "\n",
    "\n",
    "def cast(value):\n",
    "    if type(value) is pydicom.valuerep.MultiValue:\n",
    "        return tuple(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "def get_dicom_raw(dicom):\n",
    "    return {attr:cast(getattr(dicom,attr)) for attr in dir(dicom) if attr[0].isupper() and attr not in ['PixelData']}\n",
    "\n",
    "\n",
    "def rescale_image(image, slope, intercept):\n",
    "    return image * slope + intercept\n",
    "\n",
    "\n",
    "def apply_window(image, center, width):\n",
    "    image = image.copy()\n",
    "    min_value = center - width // 2\n",
    "    max_value = center + width // 2\n",
    "    image[image < min_value] = min_value\n",
    "    image[image > max_value] = max_value\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_dicom_meta(dicom):\n",
    "    return {\n",
    "        'PatientID': dicom.PatientID, # can be grouped (20-548)\n",
    "        'StudyInstanceUID': dicom.StudyInstanceUID, # can be grouped (20-60)\n",
    "        'SeriesInstanceUID': dicom.SeriesInstanceUID, # can be grouped (20-60)\n",
    "        'WindowWidth': get_dicom_value(dicom.WindowWidth),\n",
    "        'WindowCenter': get_dicom_value(dicom.WindowCenter),\n",
    "        'RescaleIntercept': float(dicom.RescaleIntercept),\n",
    "        'RescaleSlope': float(dicom.RescaleSlope), # all same (1.0)\n",
    "    }\n",
    "\n",
    "\n",
    "def apply_window_policy(image):\n",
    "\n",
    "    image1 = apply_window(image, 40, 80) # brain\n",
    "    image2 = apply_window(image, 80, 200) # subdural\n",
    "    image3 = apply_window(image, 40, 380) # bone\n",
    "    image1 = (image1 - 0) / 80\n",
    "    image2 = (image2 - (-20)) / 200\n",
    "    image3 = (image3 - (-150)) / 380\n",
    "    image = np.array([\n",
    "        image1 - image1.mean(),\n",
    "        image2 - image2.mean(),\n",
    "        image3 - image3.mean(),\n",
    "    ]).transpose(1,2,0)\n",
    "\n",
    "    return image\n",
    "\n",
    "def convert_dicom_to_jpg(name):\n",
    "    try:\n",
    "        \n",
    "        data = f.read(name)\n",
    "        dirtype = 'train' if 'train' in name else 'test'\n",
    "        imgnm = (name.split('/')[-1]).replace('.dcm', '')\n",
    "    #     print(PATHPROC+\"/\"+ imgnm+'.jpg')\n",
    "        if os.path.exists(PATHPROC +\"/\"+  imgnm + '.jpg'):\n",
    "    #             return\n",
    "            print(imgnm+\".jpg is existed.\" )\n",
    "        else:\n",
    "            dicom = pydicom.dcmread(DicomBytesIO(data))\n",
    "            image = dicom.pixel_array\n",
    "            image = rescale_image(image, rescaledict['RescaleSlope'][imgnm], rescaledict['RescaleIntercept'][imgnm])\n",
    "            image = apply_window_policy(image)\n",
    "            image -= image.min((0,1))\n",
    "            image = (255*image).astype(np.uint8)\n",
    "            cv2.imwrite(os.path.join(PATHPROC, imgnm)+'.jpg', image)\n",
    "    except:\n",
    "        logger.info(name)\n",
    "        \n",
    "def generate_df(base, files):\n",
    "    train_di = {}\n",
    "\n",
    "    for filename in tqdm(files):\n",
    "        path = os.path.join( base ,  filename)\n",
    "        dcm = pydicom.dcmread(path)\n",
    "        all_keywords = dcm.dir()\n",
    "        ignored = ['Rows', 'Columns', 'PixelData']\n",
    "\n",
    "        for name in all_keywords:\n",
    "            if name in ignored:\n",
    "                continue\n",
    "\n",
    "            if name not in train_di:\n",
    "                train_di[name] = []\n",
    "\n",
    "            train_di[name].append(dcm[name].value)\n",
    "\n",
    "    df = pd.DataFrame(train_di)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = '../data/'\n",
    "TRAIN_DIR = os.path.join(DATAPATH, 'raw/sample_png/stage_2_train')\n",
    "TEST_DIR = os.path.join(DATAPATH, 'raw/sample_png/stage_2_test')\n",
    "PATHPROC = os.path.join(DATAPATH, 'proc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-18 09:38:30,474 - Prepare Data - INFO - Create test meta files\n",
      "100%|██████████| 121232/121232 [13:42<00:00, 147.46it/s]\n",
      "2020-05-18 09:52:15,898 - Prepare Data - INFO - Create train meta files\n",
      "100%|██████████| 752803/752803 [1:20:19<00:00, 156.20it/s] \n",
      "2020-05-18 11:12:58,577 - Prepare Data - INFO - Load meta files\n",
      "2020-05-18 11:13:01,281 - Prepare Data - INFO - Train meta shape 752803 20\n",
      "2020-05-18 11:13:01,627 - Prepare Data - INFO - Test  meta shape 121232 20\n",
      "2020-05-18 11:13:03,316 - Prepare Data - INFO - Create windowed images\n",
      "  0%|          | 0/874040 [00:00<?, ?it/s]2020-05-18 11:13:11,628 - Prepare Data - INFO - rsna-intracranial-hemorrhage-detection/\n",
      "2020-05-18 11:13:11,678 - Prepare Data - INFO - rsna-intracranial-hemorrhage-detection/stage_2_sample_submission.csv\n",
      "2020-05-18 11:13:11,680 - Prepare Data - INFO - rsna-intracranial-hemorrhage-detection/stage_2_test/\n",
      " 14%|█▍        | 121233/874040 [25:44<2:37:38, 79.59it/s]2020-05-18 11:38:55,863 - Prepare Data - INFO - rsna-intracranial-hemorrhage-detection/stage_2_train/\n",
      " 64%|██████▎   | 556703/874040 [1:57:16<1:04:03, 82.57it/s]2020-05-18 13:10:27,897 - Prepare Data - INFO - rsna-intracranial-hemorrhage-detection/stage_2_train/ID_6431af929.dcm\n",
      "100%|█████████▉| 874034/874040 [3:29:04<00:00, 58.51it/s]  2020-05-18 14:42:16,260 - Prepare Data - INFO - rsna-intracranial-hemorrhage-detection/stage_2_train.csv\n",
      "100%|██████████| 874040/874040 [3:29:04<00:00, 69.67it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "logger.info('Create test meta files')\n",
    "test_files = os.listdir(TEST_DIR)\n",
    "test_df = generate_df(TEST_DIR, test_files)\n",
    "test_df.to_csv(os.path.join(DATAPATH, 'test_metadata.csv'))\n",
    "\n",
    "logger.info('Create train meta files')\n",
    "train_files = os.listdir(TRAIN_DIR)\n",
    "train_df = generate_df(TRAIN_DIR, train_files)\n",
    "train_df.to_csv(os.path.join(DATAPATH, 'train_metadata.csv'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:19:44,963 - Prepare Data - INFO - Load meta files\n",
      "2020-05-18 16:19:47,222 - Prepare Data - INFO - Train meta shape 752803 20\n",
      "2020-05-18 16:19:47,524 - Prepare Data - INFO - Test  meta shape 121232 20\n"
     ]
    }
   ],
   "source": [
    "logger.info('Load meta files')\n",
    "trnmdf = pd.read_csv(os.path.join(DATAPATH, 'train_metadata.csv'))\n",
    "logger.info('Train meta shape {} {}'.format(*trnmdf.shape))\n",
    "\n",
    "tstmdf = pd.read_csv(os.path.join(DATAPATH, 'test_metadata.csv'))\n",
    "logger.info('Test  meta shape {} {}'.format(*tstmdf.shape))\n",
    "\n",
    "\n",
    "mdf = pd.concat([trnmdf, tstmdf], 0)\n",
    "rescaledict = mdf.set_index('SOPInstanceUID')[['RescaleSlope', 'RescaleIntercept']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PATHPROC):\n",
    "    os.mkdir(PATHPROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Create windowed images')\n",
    "# with zipfile.ZipFile(os.path.join(DATAPATH, \"raw/rsna-intracranial-hemorrhage-detection.zip\"), \"r\") as f:\n",
    "with zipfile.ZipFile(os.path.join(DATAPATH, \"raw/rsna-intracranial-hemorrhage-detection.zip\"), \"r\") as f:\n",
    "    for t, name in enumerate(tqdm(f.namelist())):\n",
    "#     for t, name in enumerate(f.namelist()):\n",
    "#         print(name)\n",
    "        convert_dicom_to_jpg(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.Parallel(n_jobs=n_jobs)(joblib.delayed(pre_process_dicom)(i, output_dir, dicom_dir, data_type, width_ratio, height_ratio, skip_ratio, lr_skip_ratio) for i in list_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
